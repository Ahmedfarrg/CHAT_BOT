{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyOWMS4McAF1"
      },
      "source": [
        "# Import Liberaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q7aykQWj7_af"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NifGVcvTcHmG"
      },
      "source": [
        "Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Cp_jWjBpcHBw"
      },
      "outputs": [],
      "source": [
        "with open('data.json') as file:\n",
        "    data=json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOLkBHgtcX6o",
        "outputId": "0e9d94c2-9239-4d9f-a54c-26518b29a820"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 'greeting',\n",
              " 'patterns': ['Hi', 'Hey', 'Is anyone there?', 'Hello', 'Hay'],\n",
              " 'responses': ['Hello', 'Hi', 'Hi there', 'Hey']}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data['data'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjCHjq6vcdb_"
      },
      "source": [
        "Create training example , label and response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "H6OaYr4ccYp2"
      },
      "outputs": [],
      "source": [
        "training_example=[]\n",
        "training_labels=[]\n",
        "response=[]\n",
        "\n",
        "for example in data['data']:\n",
        "    for pattern in example['patterns']:\n",
        "        training_example.append(pattern)\n",
        "        training_labels.append(example['label'])\n",
        "    response.append(example['responses'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTpUxsAAd6HG",
        "outputId": "bed7f606-2e90-4e65-b85e-bd740414dcd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training example \n",
            "['Hi', 'Hey', 'Is anyone there?', 'Hello', 'Hay', 'Who are you?', 'What are you?', 'Who you are?', 'what is your name?', 'what should I call you?', 'whats your name?', 'Could you help me?', 'give me a hand please.', 'Can you help?', 'What can you do for me?', 'I need a support.', 'I need a help', 'support me please', \"I'm sad\", \"I'm so sad\", 'I feel bad', 'I am alone', 'I have a lot of problems', 'I am depressed', 'I need encouragement', \"I'm so frustrated\", \"I'm so frustrated with myself because I lost confidence\", 'Thanks', 'Thank you', \"That's helpful\", 'Thanks for the help', 'Bye', 'See you later', 'Goodbye']\n"
          ]
        }
      ],
      "source": [
        "print(\"training example \")\n",
        "print(training_example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCyryJznelj7",
        "outputId": "8a49b15e-85d2-4fe5-88c1-8aed433b0fc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training label \n",
            "['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'about', 'about', 'about', 'name', 'name', 'name', 'help', 'help', 'help', 'help', 'help', 'help', 'help', 'sad', 'sad', 'sad', 'sad', 'sad', 'positive_sen', 'positive_sen', 'positive_sen', 'positive_sen', 'thanks', 'thanks', 'thanks', 'thanks', 'goodbye', 'goodbye', 'goodbye']\n"
          ]
        }
      ],
      "source": [
        "print(\"training label \")\n",
        "print(training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRY8UTodeqmX",
        "outputId": "ae290e1c-ceb3-4fb8-fa3c-228733f44878"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response\n",
            "[['Hello', 'Hi', 'Hi there', 'Hey'], [\"I'm Zain, your bot assistant\", \"I'm Zain , an Artificial Intelligent bot\", \"I'm Zain , an Amit Artificial Intelligent bot\"], ['You can call me Zain.', \"I'm Zain!\", 'Just call me as Zain'], ['Tell me how can assist you', 'Tell me your problem to assist you', 'Yes Sure, How can I support you'], ['It is better for you to pray', 'Get close to Allah', 'You can watch a movie', 'Go out with friends'], ['I think you are great!', 'You are a genius!', 'You are awesome'], ['Happy to help!', 'Any time!', 'My pleasure', \"You're most welcome!\"], ['See you later', 'Have a nice day', 'Bye! Come back again']]\n"
          ]
        }
      ],
      "source": [
        "print('Response')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6bML3Ive98F",
        "outputId": "596ce744-059b-43e9-85c6-063150d235ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(training_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ColkAIftx7cE",
        "outputId": "587ec047-d1e6-4f2e-a10c-9335bbac4d30"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'about',\n",
              " 'goodbye',\n",
              " 'greeting',\n",
              " 'help',\n",
              " 'name',\n",
              " 'positive_sen',\n",
              " 'sad',\n",
              " 'thanks'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlifINfEfVoR",
        "outputId": "b0e5c419-9d8a-4628-b28f-712d4aeb04c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(set(training_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdHfsxyyfqu0"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPdtwIZRg--U"
      },
      "outputs": [],
      "source": [
        "training_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jE3LGFTdfeA3"
      },
      "outputs": [],
      "source": [
        "def clean_text(sentences):\n",
        "    result=[]\n",
        "    for sentence in sentences:\n",
        "        #sentence=re.sub(r'\\W',' ',sentence)# pattern  # text\n",
        "        sentence=sentence.lower()\n",
        "        result.append(sentence)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uZSvuySwgYXe"
      },
      "outputs": [],
      "source": [
        "training_example=clean_text(training_example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7Z0dZXjjz_T"
      },
      "source": [
        "convert label values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GxxBf1fQixNb"
      },
      "outputs": [],
      "source": [
        "le=LabelEncoder()\n",
        "le.fit(training_labels)\n",
        "training_labels=le.fit_transform(training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoI0apTHkGo2",
        "outputId": "7aa5ead1-90d7-4ecf-d182-c3677511a3ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, 2, 2, 0, 0, 0, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 6, 6, 6, 6,\n",
              "       6, 5, 5, 5, 5, 7, 7, 7, 7, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "training_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvhZCy9_qFc7",
        "outputId": "f2a2e9df-2d66-4d8c-b678-f3cb60a3206a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "training_labels=to_categorical(training_labels)\n",
        "training_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag5o05eJlujN"
      },
      "source": [
        "Convert words to vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVlOlKqVN7_a",
        "outputId": "ee080f3c-72ad-412b-d788-f2c8280bc135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[17], [29], [17, 14, 11], [47], [42], [16, 26, 44], [43, 26, 44], [16, 13, 14], [43, 17, 40, 39], [43, 24, 37, 49, 44], [2, 40, 39], [33, 13, 9, 23], [44, 38, 25, 22, 29], [46, 13, 21], [43, 46, 13, 35, 47, 23], [37, 33, 25, 27], [37, 33, 25, 9], [25, 38, 11], [14, 15], [14, 9, 15], [37, 34, 9], [37, 46, 4], [37, 32, 25, 14, 34, 45], [37, 46, 11], [37, 33, 14], [14, 9, 1], [14, 9, 1, 27, 36, 27, 37, 29, 14], [12], [15, 13], [5, 35], [12, 47, 37, 9], [19], [18, 13, 22], [17]]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "sequnces=[one_hot(example,50,filters='') for example in training_example]\n",
        "print(sequnces)\n",
        "\n",
        "# onvert text into one-hot encoded sequences\n",
        "# 50 >>>>The vocab_size parameter specifies the size of the vocabulary,\n",
        "#  and filters='' means that no characters should be filtered during tokenization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S80n4A1_kHwt",
        "outputId": "9d7e3e90-c2a3-49e0-be83-90a5cc99ff2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[23], [24], [11, 25, 26], [27], [28], [12, 8, 1], [3, 8, 1], [12, 1, 8], [3, 11, 13, 14], [3, 29, 2, 30, 1], [31, 13, 14], [32, 1, 4, 5], [33, 5, 6, 34, 15], [16, 1, 4], [3, 16, 1, 35, 17, 5], [2, 9, 6, 18], [2, 9, 6, 4], [18, 5, 15], [7, 19], [7, 10, 19], [2, 36, 37], [2, 20, 38], [2, 39, 6, 40, 41, 42], [2, 20, 43], [2, 9, 44], [7, 10, 21], [7, 10, 21, 45, 46, 47, 2, 48, 49], [22], [50, 1], [51, 52], [22, 17, 53, 4], [54], [55, 1, 56], [57]]\n"
          ]
        }
      ],
      "source": [
        "toknizer=Tokenizer(num_words=100)\n",
        "toknizer.fit_on_texts(training_example)\n",
        "sequnces=toknizer.texts_to_sequences(training_example)\n",
        "print(sequnces)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NogQSSfzmBum",
        "outputId": "311984c4-f64a-4486-c7e4-7da184933df3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 24]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11 25 26]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 28]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  8  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  8  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  1  8]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3 11 13 14]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3 29  2 30  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 31 13 14]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 32  1  4  5]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 33  5  6 34 15]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16  1  4]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  3 16  1 35 17  5]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  9  6 18]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  9  6  4]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18  5 15]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  7 19]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  7 10 19]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2 36 37]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2 20 38]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  2 39  6 40 41 42]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2 20 43]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  9 44]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  7 10 21]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  7 10 21 45 46 47  2 48 49]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 22]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 50  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 51 52]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 22 17 53  4]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 54]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 55  1 56]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 57]]\n"
          ]
        }
      ],
      "source": [
        "padded_sequence=pad_sequences(sequnces,truncating='post',maxlen=20)\n",
        "print(padded_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "yq-wIrrnmLrm"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense ,LSTM,Embedding ,GlobalAveragePooling1D\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(100,10,input_length=20))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(8,activation='softmax'))\n",
        "\n",
        "# Embedding layer It is primarily used for learning word embeddings\n",
        "\n",
        "# 100: This is the first argument, which represents the size of the vocabulary.\n",
        "#       It indicates that your model will have a vocabulary of 100 unique words or tokens.\n",
        "\n",
        "# 10: This is the second argument, which represents the dimensionality of the embedding vector\n",
        "#     for each word in the vocabulary. In this case, each word will be represented as a 10-dimensional vector.\n",
        "\n",
        "# input_length=20: This is the length of input sequences that will be fed into the Embedding layer.\n",
        "#                   It indicates that your model expects input sequences of length 20.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbTfXm2UPe1Y",
        "outputId": "3f79a83a-f327-4a51-9cfc-a5ad9d29d373"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 20, 10)            1000      \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 10)                0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                110       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 8)                 88        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1308 (5.11 KB)\n",
            "Trainable params: 1308 (5.11 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilg4_fStqnCr",
        "outputId": "2206649c-bbd4-45e9-be26-b9a600eed78e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "2/2 [==============================] - 1s 12ms/step - loss: 2.0783 - accuracy: 0.1176\n",
            "Epoch 2/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0776 - accuracy: 0.1765\n",
            "Epoch 3/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0772 - accuracy: 0.2353\n",
            "Epoch 4/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0770 - accuracy: 0.2647\n",
            "Epoch 5/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0769 - accuracy: 0.2059\n",
            "Epoch 6/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0766 - accuracy: 0.2059\n",
            "Epoch 7/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0762 - accuracy: 0.2059\n",
            "Epoch 8/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0758 - accuracy: 0.2059\n",
            "Epoch 9/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0753 - accuracy: 0.2059\n",
            "Epoch 10/400\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0748 - accuracy: 0.2059\n",
            "Epoch 11/400\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0742 - accuracy: 0.2059\n",
            "Epoch 12/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0735 - accuracy: 0.2059\n",
            "Epoch 13/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0727 - accuracy: 0.2059\n",
            "Epoch 14/400\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0720 - accuracy: 0.2059\n",
            "Epoch 15/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0712 - accuracy: 0.2059\n",
            "Epoch 16/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0704 - accuracy: 0.2059\n",
            "Epoch 17/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0696 - accuracy: 0.2059\n",
            "Epoch 18/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0688 - accuracy: 0.2059\n",
            "Epoch 19/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0682 - accuracy: 0.2059\n",
            "Epoch 20/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0676 - accuracy: 0.2059\n",
            "Epoch 21/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0669 - accuracy: 0.2059\n",
            "Epoch 22/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0663 - accuracy: 0.2059\n",
            "Epoch 23/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0656 - accuracy: 0.2059\n",
            "Epoch 24/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0650 - accuracy: 0.2059\n",
            "Epoch 25/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0645 - accuracy: 0.2059\n",
            "Epoch 26/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0640 - accuracy: 0.2059\n",
            "Epoch 27/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0635 - accuracy: 0.2059\n",
            "Epoch 28/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0629 - accuracy: 0.2059\n",
            "Epoch 29/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0622 - accuracy: 0.2059\n",
            "Epoch 30/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0614 - accuracy: 0.2059\n",
            "Epoch 31/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0608 - accuracy: 0.2059\n",
            "Epoch 32/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0600 - accuracy: 0.2059\n",
            "Epoch 33/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0594 - accuracy: 0.2059\n",
            "Epoch 34/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0588 - accuracy: 0.2059\n",
            "Epoch 35/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0583 - accuracy: 0.2059\n",
            "Epoch 36/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0578 - accuracy: 0.2059\n",
            "Epoch 37/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0571 - accuracy: 0.2059\n",
            "Epoch 38/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0565 - accuracy: 0.2059\n",
            "Epoch 39/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0558 - accuracy: 0.2059\n",
            "Epoch 40/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0552 - accuracy: 0.2059\n",
            "Epoch 41/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0545 - accuracy: 0.2059\n",
            "Epoch 42/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0539 - accuracy: 0.2059\n",
            "Epoch 43/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0532 - accuracy: 0.2059\n",
            "Epoch 44/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0523 - accuracy: 0.2059\n",
            "Epoch 45/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0514 - accuracy: 0.2059\n",
            "Epoch 46/400\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0505 - accuracy: 0.2059\n",
            "Epoch 47/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0494 - accuracy: 0.2059\n",
            "Epoch 48/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0485 - accuracy: 0.2059\n",
            "Epoch 49/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0476 - accuracy: 0.2059\n",
            "Epoch 50/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0467 - accuracy: 0.2059\n",
            "Epoch 51/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0459 - accuracy: 0.2059\n",
            "Epoch 52/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0451 - accuracy: 0.2059\n",
            "Epoch 53/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0445 - accuracy: 0.2059\n",
            "Epoch 54/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0437 - accuracy: 0.2059\n",
            "Epoch 55/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0433 - accuracy: 0.2059\n",
            "Epoch 56/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0427 - accuracy: 0.2059\n",
            "Epoch 57/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0423 - accuracy: 0.2059\n",
            "Epoch 58/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0419 - accuracy: 0.2059\n",
            "Epoch 59/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0415 - accuracy: 0.2059\n",
            "Epoch 60/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0410 - accuracy: 0.2059\n",
            "Epoch 61/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0404 - accuracy: 0.2059\n",
            "Epoch 62/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0398 - accuracy: 0.2059\n",
            "Epoch 63/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0391 - accuracy: 0.2059\n",
            "Epoch 64/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0385 - accuracy: 0.2059\n",
            "Epoch 65/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0376 - accuracy: 0.2059\n",
            "Epoch 66/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0368 - accuracy: 0.2059\n",
            "Epoch 67/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0359 - accuracy: 0.2059\n",
            "Epoch 68/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0351 - accuracy: 0.2059\n",
            "Epoch 69/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0342 - accuracy: 0.2059\n",
            "Epoch 70/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0334 - accuracy: 0.2059\n",
            "Epoch 71/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0324 - accuracy: 0.2059\n",
            "Epoch 72/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0315 - accuracy: 0.2059\n",
            "Epoch 73/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0306 - accuracy: 0.2059\n",
            "Epoch 74/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0299 - accuracy: 0.2059\n",
            "Epoch 75/400\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0289 - accuracy: 0.2059\n",
            "Epoch 76/400\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0282 - accuracy: 0.2059\n",
            "Epoch 77/400\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0278 - accuracy: 0.2059\n",
            "Epoch 78/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0273 - accuracy: 0.2059\n",
            "Epoch 79/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0266 - accuracy: 0.2059\n",
            "Epoch 80/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0261 - accuracy: 0.2059\n",
            "Epoch 81/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0257 - accuracy: 0.2059\n",
            "Epoch 82/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0256 - accuracy: 0.2059\n",
            "Epoch 83/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0254 - accuracy: 0.2059\n",
            "Epoch 84/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0252 - accuracy: 0.2059\n",
            "Epoch 85/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0249 - accuracy: 0.2059\n",
            "Epoch 86/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0243 - accuracy: 0.2059\n",
            "Epoch 87/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0236 - accuracy: 0.2059\n",
            "Epoch 88/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0232 - accuracy: 0.2059\n",
            "Epoch 89/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0225 - accuracy: 0.2059\n",
            "Epoch 90/400\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0213 - accuracy: 0.2059\n",
            "Epoch 91/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0199 - accuracy: 0.2059\n",
            "Epoch 92/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0185 - accuracy: 0.2059\n",
            "Epoch 93/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0174 - accuracy: 0.2059\n",
            "Epoch 94/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0163 - accuracy: 0.2059\n",
            "Epoch 95/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0151 - accuracy: 0.2059\n",
            "Epoch 96/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0140 - accuracy: 0.2059\n",
            "Epoch 97/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0133 - accuracy: 0.2059\n",
            "Epoch 98/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0122 - accuracy: 0.2059\n",
            "Epoch 99/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0111 - accuracy: 0.2059\n",
            "Epoch 100/400\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0100 - accuracy: 0.2059\n",
            "Epoch 101/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0088 - accuracy: 0.2059\n",
            "Epoch 102/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0077 - accuracy: 0.2059\n",
            "Epoch 103/400\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0066 - accuracy: 0.2059\n",
            "Epoch 104/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0054 - accuracy: 0.2059\n",
            "Epoch 105/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0043 - accuracy: 0.2059\n",
            "Epoch 106/400\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0032 - accuracy: 0.2353\n",
            "Epoch 107/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0024 - accuracy: 0.2353\n",
            "Epoch 108/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0016 - accuracy: 0.2353\n",
            "Epoch 109/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0002 - accuracy: 0.2353\n",
            "Epoch 110/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9988 - accuracy: 0.2353\n",
            "Epoch 111/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9970 - accuracy: 0.2353\n",
            "Epoch 112/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.9957 - accuracy: 0.2059\n",
            "Epoch 113/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.9944 - accuracy: 0.2059\n",
            "Epoch 114/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9930 - accuracy: 0.2059\n",
            "Epoch 115/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9918 - accuracy: 0.2059\n",
            "Epoch 116/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9904 - accuracy: 0.2059\n",
            "Epoch 117/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.9895 - accuracy: 0.2059\n",
            "Epoch 118/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.9881 - accuracy: 0.2059\n",
            "Epoch 119/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9869 - accuracy: 0.2059\n",
            "Epoch 120/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.9860 - accuracy: 0.2059\n",
            "Epoch 121/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.9848 - accuracy: 0.2059\n",
            "Epoch 122/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.9836 - accuracy: 0.2059\n",
            "Epoch 123/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9825 - accuracy: 0.2059\n",
            "Epoch 124/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9813 - accuracy: 0.2059\n",
            "Epoch 125/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9798 - accuracy: 0.2059\n",
            "Epoch 126/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9783 - accuracy: 0.2059\n",
            "Epoch 127/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9769 - accuracy: 0.2059\n",
            "Epoch 128/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9752 - accuracy: 0.2059\n",
            "Epoch 129/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9735 - accuracy: 0.2059\n",
            "Epoch 130/400\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9717 - accuracy: 0.2059\n",
            "Epoch 131/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9695 - accuracy: 0.2059\n",
            "Epoch 132/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9678 - accuracy: 0.2059\n",
            "Epoch 133/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9658 - accuracy: 0.2059\n",
            "Epoch 134/400\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.9640 - accuracy: 0.2059\n",
            "Epoch 135/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9623 - accuracy: 0.2059\n",
            "Epoch 136/400\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.9611 - accuracy: 0.2059\n",
            "Epoch 137/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9593 - accuracy: 0.2059\n",
            "Epoch 138/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.9576 - accuracy: 0.2059\n",
            "Epoch 139/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.9555 - accuracy: 0.2059\n",
            "Epoch 140/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.9537 - accuracy: 0.2059\n",
            "Epoch 141/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9514 - accuracy: 0.2059\n",
            "Epoch 142/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9491 - accuracy: 0.2059\n",
            "Epoch 143/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9469 - accuracy: 0.2059\n",
            "Epoch 144/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9447 - accuracy: 0.2059\n",
            "Epoch 145/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9429 - accuracy: 0.2059\n",
            "Epoch 146/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9407 - accuracy: 0.2059\n",
            "Epoch 147/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9387 - accuracy: 0.2059\n",
            "Epoch 148/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9367 - accuracy: 0.2353\n",
            "Epoch 149/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9347 - accuracy: 0.2353\n",
            "Epoch 150/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9323 - accuracy: 0.2353\n",
            "Epoch 151/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9305 - accuracy: 0.2059\n",
            "Epoch 152/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9288 - accuracy: 0.2059\n",
            "Epoch 153/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9267 - accuracy: 0.2059\n",
            "Epoch 154/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9245 - accuracy: 0.2059\n",
            "Epoch 155/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9225 - accuracy: 0.2059\n",
            "Epoch 156/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9209 - accuracy: 0.2059\n",
            "Epoch 157/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9194 - accuracy: 0.2059\n",
            "Epoch 158/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9180 - accuracy: 0.2059\n",
            "Epoch 159/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9158 - accuracy: 0.2059\n",
            "Epoch 160/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.9134 - accuracy: 0.2059\n",
            "Epoch 161/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.9114 - accuracy: 0.2059\n",
            "Epoch 162/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.9091 - accuracy: 0.2059\n",
            "Epoch 163/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9073 - accuracy: 0.2059\n",
            "Epoch 164/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9052 - accuracy: 0.2059\n",
            "Epoch 165/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9031 - accuracy: 0.2353\n",
            "Epoch 166/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9009 - accuracy: 0.2353\n",
            "Epoch 167/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8989 - accuracy: 0.2353\n",
            "Epoch 168/400\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8967 - accuracy: 0.2353\n",
            "Epoch 169/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.8944 - accuracy: 0.2353\n",
            "Epoch 170/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8922 - accuracy: 0.2353\n",
            "Epoch 171/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8895 - accuracy: 0.2353\n",
            "Epoch 172/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8871 - accuracy: 0.2353\n",
            "Epoch 173/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8842 - accuracy: 0.2353\n",
            "Epoch 174/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8815 - accuracy: 0.2353\n",
            "Epoch 175/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8787 - accuracy: 0.2353\n",
            "Epoch 176/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8759 - accuracy: 0.2353\n",
            "Epoch 177/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8731 - accuracy: 0.2647\n",
            "Epoch 178/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8703 - accuracy: 0.2647\n",
            "Epoch 179/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8670 - accuracy: 0.2647\n",
            "Epoch 180/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8635 - accuracy: 0.2941\n",
            "Epoch 181/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8605 - accuracy: 0.2941\n",
            "Epoch 182/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8576 - accuracy: 0.2941\n",
            "Epoch 183/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8549 - accuracy: 0.4706\n",
            "Epoch 184/400\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8523 - accuracy: 0.4706\n",
            "Epoch 185/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8500 - accuracy: 0.4706\n",
            "Epoch 186/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8475 - accuracy: 0.5000\n",
            "Epoch 187/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8441 - accuracy: 0.5000\n",
            "Epoch 188/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8401 - accuracy: 0.4706\n",
            "Epoch 189/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8364 - accuracy: 0.3824\n",
            "Epoch 190/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.8333 - accuracy: 0.3824\n",
            "Epoch 191/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8296 - accuracy: 0.3824\n",
            "Epoch 192/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8259 - accuracy: 0.3824\n",
            "Epoch 193/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8226 - accuracy: 0.3824\n",
            "Epoch 194/400\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.8183 - accuracy: 0.3824\n",
            "Epoch 195/400\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8131 - accuracy: 0.3824\n",
            "Epoch 196/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8081 - accuracy: 0.3824\n",
            "Epoch 197/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8034 - accuracy: 0.3824\n",
            "Epoch 198/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7987 - accuracy: 0.3824\n",
            "Epoch 199/400\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.7937 - accuracy: 0.3824\n",
            "Epoch 200/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7892 - accuracy: 0.3824\n",
            "Epoch 201/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7852 - accuracy: 0.3824\n",
            "Epoch 202/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7819 - accuracy: 0.3824\n",
            "Epoch 203/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7781 - accuracy: 0.4118\n",
            "Epoch 204/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7743 - accuracy: 0.3824\n",
            "Epoch 205/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7700 - accuracy: 0.3824\n",
            "Epoch 206/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7657 - accuracy: 0.3824\n",
            "Epoch 207/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7615 - accuracy: 0.3824\n",
            "Epoch 208/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7570 - accuracy: 0.3824\n",
            "Epoch 209/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7534 - accuracy: 0.3824\n",
            "Epoch 210/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7505 - accuracy: 0.3824\n",
            "Epoch 211/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7472 - accuracy: 0.3824\n",
            "Epoch 212/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.7443 - accuracy: 0.3824\n",
            "Epoch 213/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7411 - accuracy: 0.3824\n",
            "Epoch 214/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7392 - accuracy: 0.3824\n",
            "Epoch 215/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7365 - accuracy: 0.3824\n",
            "Epoch 216/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7319 - accuracy: 0.3824\n",
            "Epoch 217/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7260 - accuracy: 0.3824\n",
            "Epoch 218/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.7197 - accuracy: 0.3824\n",
            "Epoch 219/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7137 - accuracy: 0.3824\n",
            "Epoch 220/400\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.7094 - accuracy: 0.3824\n",
            "Epoch 221/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7061 - accuracy: 0.3824\n",
            "Epoch 222/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7019 - accuracy: 0.3824\n",
            "Epoch 223/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6981 - accuracy: 0.3824\n",
            "Epoch 224/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6937 - accuracy: 0.3824\n",
            "Epoch 225/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6889 - accuracy: 0.3824\n",
            "Epoch 226/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6843 - accuracy: 0.3824\n",
            "Epoch 227/400\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6795 - accuracy: 0.3824\n",
            "Epoch 228/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6754 - accuracy: 0.3824\n",
            "Epoch 229/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.6710 - accuracy: 0.3824\n",
            "Epoch 230/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.6667 - accuracy: 0.3824\n",
            "Epoch 231/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6639 - accuracy: 0.3824\n",
            "Epoch 232/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.6608 - accuracy: 0.4118\n",
            "Epoch 233/400\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6598 - accuracy: 0.4706\n",
            "Epoch 234/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6588 - accuracy: 0.4412\n",
            "Epoch 235/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6571 - accuracy: 0.4118\n",
            "Epoch 236/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6546 - accuracy: 0.3824\n",
            "Epoch 237/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.6499 - accuracy: 0.3824\n",
            "Epoch 238/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6445 - accuracy: 0.4412\n",
            "Epoch 239/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6389 - accuracy: 0.5000\n",
            "Epoch 240/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6339 - accuracy: 0.5000\n",
            "Epoch 241/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6285 - accuracy: 0.4706\n",
            "Epoch 242/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6239 - accuracy: 0.4706\n",
            "Epoch 243/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.6196 - accuracy: 0.4706\n",
            "Epoch 244/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6153 - accuracy: 0.4706\n",
            "Epoch 245/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6111 - accuracy: 0.4412\n",
            "Epoch 246/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6069 - accuracy: 0.4412\n",
            "Epoch 247/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6026 - accuracy: 0.4412\n",
            "Epoch 248/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5980 - accuracy: 0.5000\n",
            "Epoch 249/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5935 - accuracy: 0.5000\n",
            "Epoch 250/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5893 - accuracy: 0.5000\n",
            "Epoch 251/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5850 - accuracy: 0.5294\n",
            "Epoch 252/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5809 - accuracy: 0.5294\n",
            "Epoch 253/400\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.5766 - accuracy: 0.5294\n",
            "Epoch 254/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5724 - accuracy: 0.5294\n",
            "Epoch 255/400\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.5687 - accuracy: 0.5294\n",
            "Epoch 256/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5643 - accuracy: 0.5294\n",
            "Epoch 257/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5597 - accuracy: 0.5294\n",
            "Epoch 258/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5560 - accuracy: 0.5294\n",
            "Epoch 259/400\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5520 - accuracy: 0.5294\n",
            "Epoch 260/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5466 - accuracy: 0.5294\n",
            "Epoch 261/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5407 - accuracy: 0.5294\n",
            "Epoch 262/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5344 - accuracy: 0.5294\n",
            "Epoch 263/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5278 - accuracy: 0.5294\n",
            "Epoch 264/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5215 - accuracy: 0.5294\n",
            "Epoch 265/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5159 - accuracy: 0.5294\n",
            "Epoch 266/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5096 - accuracy: 0.5294\n",
            "Epoch 267/400\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5035 - accuracy: 0.5294\n",
            "Epoch 268/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4978 - accuracy: 0.5294\n",
            "Epoch 269/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4913 - accuracy: 0.5294\n",
            "Epoch 270/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4855 - accuracy: 0.5294\n",
            "Epoch 271/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.4800 - accuracy: 0.5294\n",
            "Epoch 272/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4748 - accuracy: 0.5294\n",
            "Epoch 273/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4693 - accuracy: 0.5294\n",
            "Epoch 274/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4631 - accuracy: 0.5294\n",
            "Epoch 275/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4574 - accuracy: 0.5294\n",
            "Epoch 276/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4529 - accuracy: 0.5294\n",
            "Epoch 277/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.4484 - accuracy: 0.5294\n",
            "Epoch 278/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4435 - accuracy: 0.5294\n",
            "Epoch 279/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4378 - accuracy: 0.5294\n",
            "Epoch 280/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4326 - accuracy: 0.5294\n",
            "Epoch 281/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4275 - accuracy: 0.5294\n",
            "Epoch 282/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4227 - accuracy: 0.5294\n",
            "Epoch 283/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4175 - accuracy: 0.5294\n",
            "Epoch 284/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4127 - accuracy: 0.5294\n",
            "Epoch 285/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4082 - accuracy: 0.5294\n",
            "Epoch 286/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4050 - accuracy: 0.5294\n",
            "Epoch 287/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4012 - accuracy: 0.5294\n",
            "Epoch 288/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3989 - accuracy: 0.5294\n",
            "Epoch 289/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3969 - accuracy: 0.5294\n",
            "Epoch 290/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3965 - accuracy: 0.5294\n",
            "Epoch 291/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.3942 - accuracy: 0.5294\n",
            "Epoch 292/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3905 - accuracy: 0.5294\n",
            "Epoch 293/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3859 - accuracy: 0.5294\n",
            "Epoch 294/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3794 - accuracy: 0.5294\n",
            "Epoch 295/400\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.3718 - accuracy: 0.5294\n",
            "Epoch 296/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3645 - accuracy: 0.5294\n",
            "Epoch 297/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3582 - accuracy: 0.5294\n",
            "Epoch 298/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3526 - accuracy: 0.5294\n",
            "Epoch 299/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3488 - accuracy: 0.5294\n",
            "Epoch 300/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3438 - accuracy: 0.5294\n",
            "Epoch 301/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3385 - accuracy: 0.5294\n",
            "Epoch 302/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3325 - accuracy: 0.5294\n",
            "Epoch 303/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3261 - accuracy: 0.5294\n",
            "Epoch 304/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3217 - accuracy: 0.5294\n",
            "Epoch 305/400\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3189 - accuracy: 0.5294\n",
            "Epoch 306/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.3166 - accuracy: 0.5294\n",
            "Epoch 307/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3143 - accuracy: 0.5294\n",
            "Epoch 308/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3109 - accuracy: 0.5294\n",
            "Epoch 309/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3052 - accuracy: 0.5294\n",
            "Epoch 310/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2975 - accuracy: 0.5294\n",
            "Epoch 311/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.2899 - accuracy: 0.5294\n",
            "Epoch 312/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2833 - accuracy: 0.5294\n",
            "Epoch 313/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2781 - accuracy: 0.5294\n",
            "Epoch 314/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2757 - accuracy: 0.5294\n",
            "Epoch 315/400\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2728 - accuracy: 0.5294\n",
            "Epoch 316/400\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.2689 - accuracy: 0.5294\n",
            "Epoch 317/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2648 - accuracy: 0.5294\n",
            "Epoch 318/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2608 - accuracy: 0.5588\n",
            "Epoch 319/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2571 - accuracy: 0.5588\n",
            "Epoch 320/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2544 - accuracy: 0.5588\n",
            "Epoch 321/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2505 - accuracy: 0.5588\n",
            "Epoch 322/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2446 - accuracy: 0.5588\n",
            "Epoch 323/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2380 - accuracy: 0.5588\n",
            "Epoch 324/400\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.2317 - accuracy: 0.5294\n",
            "Epoch 325/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2271 - accuracy: 0.5294\n",
            "Epoch 326/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2235 - accuracy: 0.5294\n",
            "Epoch 327/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2199 - accuracy: 0.5294\n",
            "Epoch 328/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2147 - accuracy: 0.5294\n",
            "Epoch 329/400\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2093 - accuracy: 0.5294\n",
            "Epoch 330/400\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2046 - accuracy: 0.5294\n",
            "Epoch 331/400\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.2001 - accuracy: 0.5294\n",
            "Epoch 332/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1958 - accuracy: 0.5294\n",
            "Epoch 333/400\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1919 - accuracy: 0.5294\n",
            "Epoch 334/400\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1886 - accuracy: 0.5294\n",
            "Epoch 335/400\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1855 - accuracy: 0.5294\n",
            "Epoch 336/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1817 - accuracy: 0.5294\n",
            "Epoch 337/400\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1780 - accuracy: 0.5588\n",
            "Epoch 338/400\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1737 - accuracy: 0.5588\n",
            "Epoch 339/400\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1692 - accuracy: 0.5294\n",
            "Epoch 340/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1647 - accuracy: 0.5882\n",
            "Epoch 341/400\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1608 - accuracy: 0.5882\n",
            "Epoch 342/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1562 - accuracy: 0.5882\n",
            "Epoch 343/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1522 - accuracy: 0.5882\n",
            "Epoch 344/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1473 - accuracy: 0.5882\n",
            "Epoch 345/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1431 - accuracy: 0.5588\n",
            "Epoch 346/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1391 - accuracy: 0.5588\n",
            "Epoch 347/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1355 - accuracy: 0.5588\n",
            "Epoch 348/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1313 - accuracy: 0.5588\n",
            "Epoch 349/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1277 - accuracy: 0.5588\n",
            "Epoch 350/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1242 - accuracy: 0.5882\n",
            "Epoch 351/400\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1210 - accuracy: 0.5882\n",
            "Epoch 352/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1162 - accuracy: 0.5882\n",
            "Epoch 353/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1116 - accuracy: 0.6176\n",
            "Epoch 354/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1066 - accuracy: 0.6176\n",
            "Epoch 355/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1028 - accuracy: 0.6176\n",
            "Epoch 356/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0996 - accuracy: 0.6176\n",
            "Epoch 357/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0969 - accuracy: 0.6176\n",
            "Epoch 358/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0935 - accuracy: 0.6176\n",
            "Epoch 359/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0892 - accuracy: 0.6176\n",
            "Epoch 360/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0847 - accuracy: 0.6176\n",
            "Epoch 361/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0804 - accuracy: 0.6176\n",
            "Epoch 362/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0769 - accuracy: 0.6176\n",
            "Epoch 363/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0736 - accuracy: 0.6176\n",
            "Epoch 364/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0708 - accuracy: 0.6176\n",
            "Epoch 365/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0678 - accuracy: 0.6176\n",
            "Epoch 366/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0648 - accuracy: 0.6176\n",
            "Epoch 367/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0620 - accuracy: 0.6176\n",
            "Epoch 368/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0596 - accuracy: 0.6176\n",
            "Epoch 369/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0568 - accuracy: 0.6176\n",
            "Epoch 370/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0536 - accuracy: 0.6176\n",
            "Epoch 371/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0501 - accuracy: 0.6176\n",
            "Epoch 372/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0456 - accuracy: 0.6176\n",
            "Epoch 373/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0401 - accuracy: 0.6176\n",
            "Epoch 374/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0353 - accuracy: 0.6176\n",
            "Epoch 375/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0313 - accuracy: 0.6176\n",
            "Epoch 376/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0269 - accuracy: 0.6176\n",
            "Epoch 377/400\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0233 - accuracy: 0.6471\n",
            "Epoch 378/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0202 - accuracy: 0.6471\n",
            "Epoch 379/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0165 - accuracy: 0.6471\n",
            "Epoch 380/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0133 - accuracy: 0.6471\n",
            "Epoch 381/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0098 - accuracy: 0.6471\n",
            "Epoch 382/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0064 - accuracy: 0.6471\n",
            "Epoch 383/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0034 - accuracy: 0.6471\n",
            "Epoch 384/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0003 - accuracy: 0.6471\n",
            "Epoch 385/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9971 - accuracy: 0.6471\n",
            "Epoch 386/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9936 - accuracy: 0.6471\n",
            "Epoch 387/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9906 - accuracy: 0.6471\n",
            "Epoch 388/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9882 - accuracy: 0.6471\n",
            "Epoch 389/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9854 - accuracy: 0.6471\n",
            "Epoch 390/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9819 - accuracy: 0.6471\n",
            "Epoch 391/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9777 - accuracy: 0.6471\n",
            "Epoch 392/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9741 - accuracy: 0.6471\n",
            "Epoch 393/400\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9708 - accuracy: 0.6471\n",
            "Epoch 394/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9673 - accuracy: 0.6471\n",
            "Epoch 395/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9636 - accuracy: 0.6471\n",
            "Epoch 396/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9599 - accuracy: 0.6471\n",
            "Epoch 397/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9567 - accuracy: 0.6471\n",
            "Epoch 398/400\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9536 - accuracy: 0.6471\n",
            "Epoch 399/400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9507 - accuracy: 0.6471\n",
            "Epoch 400/400\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9479 - accuracy: 0.6471\n"
          ]
        }
      ],
      "source": [
        "history=model.fit(np.array(padded_sequence),training_labels,epochs=400)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMigw85Xrt6O"
      },
      "source": [
        "Save Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp='hello'\n",
        "sent=pad_sequences(toknizer.texts_to_sequences([inp]),maxlen=20)\n",
        "print(sent)\n",
        "result=np.argmax(model.predict(np.array(sent))) # 0-7\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P4b1mfEQD5z",
        "outputId": "fb66c573-085a-402e-c3ee-50a6ff9a5b44"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27]]\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXwyMxiGvVXU",
        "outputId": "9a894c8c-ba8b-4c52-89a6-c75c85648219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['greeting']\n"
          ]
        }
      ],
      "source": [
        "#get the label from encoder\n",
        "f_res=le.inverse_transform(np.array(result).reshape(1))\n",
        "print(f_res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFKCsHPEN7_c"
      },
      "source": [
        "## Save Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "waktzjn0N7_d"
      },
      "outputs": [],
      "source": [
        "import pickle as pk\n",
        "#save tokinizer\n",
        "pk.dump(toknizer,open(\"toknizer.pkl\",\"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "xhEgH47lN7_d"
      },
      "outputs": [],
      "source": [
        "#save encoder\n",
        "pk.dump(le,open(\"label_encoder.pkl\",\"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Nyz31ew_rtbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21ca0694-9437-446f-e385-64f1e427f200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('model.h5') # save model\n",
        "from tensorflow.keras.models import load_model\n",
        "model=load_model('model.h5') # load model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2YhYdDXrq9h"
      },
      "source": [
        "Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "RIjWXav_q_13"
      },
      "outputs": [],
      "source": [
        "def user_chat():\n",
        "    while True :\n",
        "        print(\"User : \",end=\"\")\n",
        "        inp=input()\n",
        "\n",
        "        if inp.lower()=='quit':\n",
        "            break\n",
        "\n",
        "        sent=pad_sequences(toknizer.texts_to_sequences([inp]),maxlen=20) #[] len=20\n",
        "\n",
        "        result=np.argmax(model.predict(np.array(sent),verbose=0)) # 0-7\n",
        "        # 2 ,3 , 4\n",
        "        f_res=le.inverse_transform(np.array(result).reshape(1))\n",
        "\n",
        "\n",
        "        for label in data['data']:\n",
        "\n",
        "            if label['label']==f_res:\n",
        "\n",
        "                print('ChatBot : ',np.random.choice(label['responses']))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "glDzWm4Qtsol",
        "outputId": "ee9ac1ee-a806-420a-b772-39711391f062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Conversation with Chatbot\n",
            "User : hello\n",
            "ChatBot :  Hi there\n",
            "User : how are you\n",
            "ChatBot :  Hi\n",
            "User : "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-f0f6557df37e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start Conversation with Chatbot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muser_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-5f1f65c6417f>\u001b[0m in \u001b[0;36muser_chat\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"User : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0minp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'quit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "print(\"Start Conversation with Chatbot\")\n",
        "user_chat()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEJvo_PmtzPx"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "\n",
        "# Example text\n",
        "text_example = \"This is a simple example for one-hot encoding.\"\n",
        "\n",
        "# Perform one-hot encoding with a vocabulary size of 15\n",
        "vocab_size = 15\n",
        "encoded_sequence = one_hot(text_example, vocab_size, filters='')\n",
        "\n",
        "# Display the results\n",
        "print(f\"Original Text: {text_example}\")\n",
        "print(f\"One-Hot Encoded Sequence: {encoded_sequence}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XaDTBb7qy8ej"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}